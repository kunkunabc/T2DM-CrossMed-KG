# python 03_predict_drugs.py

import os
from tqdm import tqdm
import torch
from heapq import heappush, heappop
from pykeen.triples import TriplesFactory


def batch_score(model, triples, batch_size=2048):
    """åˆ†æ‰¹æ‰“åˆ†å¹¶è¿”å›æ‰€æœ‰åˆ†æ•° CPU å¼ é‡åˆ—è¡¨"""
    scores = []
    for i in range(0, len(triples), batch_size):
        batch = triples[i:i + batch_size]
        with torch.no_grad():
            s = model.score_hrt(batch).squeeze().cpu()
        scores.append(s)
        del batch, s
    return torch.cat(scores)


def stream_extract_topk_fullinfo(src_csv, top_k, out_csv):
    """
    ä½å†…å­˜æ¨¡å¼æµå¼æå– TopKï¼Œä¿ç•™å®Œæ•´å­—æ®µ
    è¾“å‡ºæ–‡ä»¶åˆ—ï¼šquery,relation,direction,entity,score,rank
    """
    heap = []  # min-heap ä¸­å­˜ (score, parts)
    seen = set()  # å·²æ”¶å½•å®ä½“
    with open(src_csv, 'r', encoding='utf-8') as fin:
        header = fin.readline()  # skip header
        for line in tqdm(fin, desc=f"æå– Top{top_k}", unit="è¡Œ"):
            parts = line.rstrip('\n').split(',')
            if len(parts) != 6:
                continue
            query, relation, direction, entity, score_str, rank = parts
            if entity in seen:
                continue
            try:
                score = float(score_str)
            except ValueError:
                continue
            if len(heap) < top_k:
                heappush(heap, (score, parts))
                seen.add(entity)
            elif score > heap[0][0]:
                _, removed = heappop(heap)
                seen.remove(removed[3])
                heappush(heap, (score, parts))
                seen.add(entity)

    # æ’åºå¹¶å†™å‡º
    top = sorted(heap, key=lambda x: x[0], reverse=True)
    with open(out_csv, 'w', encoding='utf-8') as fout:
        fout.write("query,relation,direction,entity,score,rank\n")
        for _, parts in top:
            fout.write(','.join(parts) + '\n')
    print(f"âœ… Top{top_k} æå–å®Œæ¯•ï¼Œä¿å­˜è‡³: {out_csv}")


def predict_for_set(label, drug_list, tf, model, device, output_dir):
    """å¯¹ä¸€ç»„å€™é€‰ drug_list é¢„æµ‹å¹¶å†™å…¥ incremental CSVï¼Œè¿”å›è¯¥ CSV è·¯å¾„"""
    ids = torch.tensor([tf.entity_to_id[e] for e in drug_list], device=device)
    num = len(ids)
    output_file = os.path.join(output_dir, f"predicted_drugs_{label}.csv")
    # å†™è¡¨å¤´
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("query,relation,direction,entity,score,rank\n")

    # åŒ…å«æ‰€æœ‰6ç§å…³ç³»
    forward_rels = ["binds", "downregulates", "upregulates", "functions", "is_associated_with"]

    for gene in tqdm(diabetes_genes, desc=f'[{label}] åŸºå› ', unit='gene'):
        if gene not in tf.entity_to_id:
            continue
        gid = tf.entity_to_id[gene]

        for rel in forward_rels:
            if rel not in tf.relation_to_id:
                continue
            rid = tf.relation_to_id[rel]
            direction = "hâ†’t"  # ç»Ÿä¸€æ–¹å‘æ ‡è®°

            # === æ ¹æ®å…³ç³»ç±»å‹åŠ¨æ€æ„å»ºä¸‰å…ƒç»„ ===
            if rel == "is_associated_with":
                # ä¸­è¯å€™é€‰é›†ç‰¹æ®Šå¤„ç†ï¼š"ä¸­è¯ï¼šå…³è”ï¼šåŸºå› " (h:ä¸­è¯, r:å…³è”, t:åŸºå› )
                if label == 'tcm':
                    h = ids
                    r = torch.full((num,), rid, device=device)
                    t = torch.full((num,), gid, device=device)
                    triples = torch.stack([h, r, t], dim=1)
                # å…¶ä»–å€™é€‰é›†ï¼š"åŸºå› ï¼šå…³è”ï¼šåŒ–åˆç‰©" (h:åŸºå› , r:å…³è”, t:åŒ–åˆç‰©)
                else:
                    h = torch.full((num,), gid, device=device)
                    r = torch.full((num,), rid, device=device)
                    t = ids
                    triples = torch.stack([h, r, t], dim=1)
            else:
                # å…¶ä»–å…³ç³»ç»Ÿä¸€æ ¼å¼ï¼š"åŒ–åˆç‰©ï¼šå…³ç³»ï¼šåŸºå› " (h:åŒ–åˆç‰©, r:å…³ç³», t:åŸºå› )
                h = ids
                r = torch.full((num,), rid, device=device)
                t = torch.full((num,), gid, device=device)
                triples = torch.stack([h, r, t], dim=1)
            # ==============================

            # åˆ†æ‰¹æ‰“åˆ†
            scores = batch_score(model, triples)
            sorted_scores, idxs = torch.sort(scores, descending=True)
            sorted_scores = sorted_scores.numpy()
            idxs = idxs.numpy().astype(int)

            # é€è¡Œå†™å…¥
            with open(output_file, 'a', encoding='utf-8') as f:
                for rank, i in enumerate(idxs, 1):
                    f.write(f"{gene},{rel},{direction},{drug_list[i]},{sorted_scores[rank - 1]},{rank}\n")

            # é‡Šæ”¾èµ„æº
            del triples, scores, sorted_scores, idxs
            torch.cuda.empty_cache()

    print(f"âœ” [{label}] é¢„æµ‹å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {output_file}")
    return output_file


if __name__ == "__main__":
    # â€”â€”â€” è·¯å¾„é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    train_path = os.path.join(project_dir, "splits", "train.tsv")
    gene_path = os.path.join(project_dir, "data", "DM_Gene.txt")
    paths = {
        'all': os.path.join(project_dir, "data", "All_Drug.txt"),
        'tcm': os.path.join(project_dir, "data", "TCM_Drug.txt"),
        'western': os.path.join(project_dir, "data", "MM_Drug.txt"),
    }
    output_dir = os.path.join(project_dir, "results", "predictions")
    os.makedirs(output_dir, exist_ok=True)

    # â€”â€”â€” åŠ è½½ TriplesFactory & æ¨¡å‹ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    tf = TriplesFactory.from_path(train_path, create_inverse_triples=False)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = torch.load(os.path.join(project_dir, "results", "RotatE", "trained_model.pkl"),
                       map_location=device)
    model.to(device).eval()

    # â€”â€”â€” è¯»å–ç³–å°¿ç—…åŸºå›  â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    with open(gene_path, 'r', encoding='utf-8') as f:
        diabetes_genes = [l.strip() for l in f if l.strip()]

    # â€”â€”â€” ä¾æ¬¡é¢„æµ‹ä¸‰ç»„å€™é€‰é›† â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    outputs = {}
    for label, path in paths.items():
        with open(path, 'r', encoding='utf-8') as f:
            drugs = [l.strip() for l in f
                     if l.strip() and l.strip() in tf.entity_to_id]
        if not drugs:
            print(f"âš ï¸ [{label}] å€™é€‰å®ä½“ä¸ºç©ºï¼Œå·²è·³è¿‡")
            continue
        outputs[label] = predict_for_set(label, drugs, tf, model, device, output_dir)

    # â€”â€”â€” æµå¼æå– TopKï¼ˆä¿ç•™å®Œæ•´å­—æ®µï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    topk_config = {'all': 200, 'tcm': 100, 'western': 200}
    for label, src in outputs.items():
        topk = topk_config[label]
        top_csv = os.path.join(output_dir, f"top{topk}_{label}.csv")
        stream_extract_topk_fullinfo(src, topk, top_csv)

    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
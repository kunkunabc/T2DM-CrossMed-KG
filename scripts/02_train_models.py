# python 02_train_models.py
import logging
import pprint
import torch
import os
import time
import math
import numpy as np
from pathlib import Path
from typing import Dict, Optional

from ruamel import yaml
from pykeen.pipeline import pipeline
from pykeen.models import Model
from pykeen.training.callbacks import TrainingCallback
from pykeen.evaluation import RankBasedEvaluator
from pykeen.triples import TriplesFactory

# === å¹³å° & æ ¹ç›®å½• ===
AUTODL_PLATFORM = os.path.exists("/root/autodl-tmp/DM_Project")
PERSISTENT_ROOT = Path("/root/autodl-tmp/DM_Project") if AUTODL_PLATFORM else Path(__file__).parent.parent.resolve()

# === æ—¥å¿—é…ç½® ===
LOG_PATH = PERSISTENT_ROOT / "training.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(LOG_PATH, encoding="utf-8"),
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)


# === åŠ¨æ€æ—©åœå›è°ƒ ===
class EarlyStoppingCallback(TrainingCallback):
    def __init__(self, patience: int = 5, delta: float = 0.001, metric: str = "Hits@10"):
        super().__init__()
        self.patience = patience
        self.delta = delta
        self.metric = metric
        self.best_value = -np.inf
        self.counter = 0
        self.early_stop = False

    def on_epoch_end(self, epoch: int, **kwargs):
        current_value = kwargs.get(self.metric, None)
        if current_value is None:
            logger.warning(f"æ— æ³•è·å–æŒ‡æ ‡ {self.metric}ï¼Œæ—©åœæœªå¯ç”¨")
            return

        if (current_value - self.best_value) > self.delta:
            self.best_value = current_value
            self.counter = 0
            logger.info(f"âœ… æŒ‡æ ‡æå‡è‡³ {self.best_value:.4f}ï¼Œé‡ç½®æ—©åœè®¡æ•°å™¨")
        else:
            self.counter += 1
            logger.info(f"â³ æŒ‡æ ‡æœªæå‡ï¼Œæ—©åœè®¡æ•°å™¨: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
                logger.warning(f"ğŸš¨ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒï¼æœ€ä½³ {self.metric} = {self.best_value:.4f}")

    def should_stop(self) -> bool:
        return self.early_stop


# === ä¼˜åŒ–åçš„æ£€æŸ¥ç‚¹å›è°ƒ ===
class PlatformCheckpointCallback(TrainingCallback):
    def __init__(self, model_name: str, results_dir: Path, metric: str = "Hits@10"):
        super().__init__()
        self.ckpt_dir = results_dir / model_name / "checkpoints"
        # å¼ºåˆ¶åˆ›å»ºç›®å½•å¹¶è®¾ç½®æƒé™
        self.ckpt_dir.mkdir(parents=True, exist_ok=True, mode=0o755)
        logger.info(f"æ£€æŸ¥ç‚¹ç›®å½•: {self.ckpt_dir.absolute()} (æƒé™: {oct(os.stat(self.ckpt_dir).st_mode & 0o777)})")
        self.best_metric = -np.inf
        self.metric = metric

    def on_epoch_end(self, epoch: int, **kwargs):
        current_value = kwargs.get(self.metric, None)
        if current_value is None:
            logger.warning(f"æœªæ”¶åˆ°æŒ‡æ ‡ {self.metric}ï¼Œè·³è¿‡æ£€æŸ¥ç‚¹ä¿å­˜")
            return

        logger.info(f"[{self.metric}] å½“å‰å€¼: {current_value:.4f}, æœ€ä½³å€¼: {self.best_metric:.4f}")
        if current_value > self.best_metric + 1e-6:  # é¿å…æµ®ç‚¹è¯¯å·®
            self.best_metric = current_value
            model = kwargs["model"]
            path = self.ckpt_dir / f"best_{self.metric.replace('@', '_')}.pt"
            try:
                # ä¿å­˜å®Œæ•´æ¨¡å‹ï¼ˆåŒ…æ‹¬ç»“æ„å’Œå‚æ•°ï¼‰
                torch.save({
                    "epoch": epoch + 1,
                    "model_state_dict": model.state_dict(),
                    "metric": self.metric,
                    "value": current_value
                }, path)
                logger.info(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {path}")
                if AUTODL_PLATFORM:
                    os.system(f"autodl sync {self.ckpt_dir} > /dev/null 2>&1")
            except Exception as e:
                logger.error(f"ä¿å­˜å¤±è´¥: {e}")


# === åŠ è½½é…ç½® ===
def load_config() -> tuple[Dict, Path]:
    cfg_path = PERSISTENT_ROOT / "configs" / "default.yaml"
    if not cfg_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {cfg_path}")
    with open(cfg_path, "r", encoding="utf-8") as f:
        cfg = yaml.YAML(typ="safe", pure=True).load(f)
    cfg["training"]["device"] = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"âœ” é…ç½®åŠ è½½æˆåŠŸ:\n{pprint.pformat(cfg)}")
    return cfg, PERSISTENT_ROOT


# === å•æ¨¡å‹è®­ç»ƒæµç¨‹ ===
def train_model(model_name: str, cfg: Dict, project_root: Path) -> Dict:
    logger.info(f"\n=== å¼€å§‹è®­ç»ƒï¼š{model_name} ===")
    splits_dir = project_root / "splits"
    results_dir = project_root / "results"
    model_dir = results_dir / model_name
    model_dir.mkdir(parents=True, exist_ok=True, mode=0o755)
    logger.info(f"æ¨¡å‹ç›®å½•: {model_dir.absolute()}")

    # åŠ¨æ€é€‰æ‹©æŸå¤±å‡½æ•°
    loss_config = {
        "ComplEx": ("marginranking", {"margin": 6.0}),
        "DistMult": ("bcewithlogits", {}),
        "RotatE": ("marginranking", {"margin": 6.0}),
    }
    loss_name, loss_kwargs = loss_config.get(model_name, ("bcewithlogits", {}))

    # åˆå§‹åŒ–å›è°ƒ
    early_stop_callback = EarlyStoppingCallback(
        patience=cfg["early_stopping"]["patience"],
        delta=cfg["early_stopping"]["delta"],
        metric=cfg["early_stopping"]["monitor_metric"],
    )
    checkpoint_callback = PlatformCheckpointCallback(
        model_name, results_dir, metric=cfg["early_stopping"]["monitor_metric"],
    )

    # === æ–°å¢ï¼šä¸´æ—¶å¯ç”¨ PyKEEN è¯¦ç»†æ—¥å¿— ===
    # ä¿å­˜å½“å‰æ—¥å¿—çº§åˆ«
    original_level = logging.getLogger("pykeen").level

    # è®¾ç½® PyKEEN æ—¥å¿—çº§åˆ«ä¸º INFO ä»¥æ˜¾ç¤ºè¯¦ç»†å‚æ•°
    logging.getLogger("pykeen").setLevel(logging.INFO)
    logging.getLogger("pykeen.pipeline").setLevel(logging.INFO)
    # === ç»“æŸæ–°å¢éƒ¨åˆ† ===

    # æ„é€ è®­ç»ƒå‚æ•°
    pipeline_args = {
        "training": str(splits_dir / "train.tsv"),
        "validation": str(splits_dir / "valid.tsv"),
        "testing": str(splits_dir / "test.tsv"),
        "model": model_name,
        "model_kwargs": {"embedding_dim": cfg["training"]["embedding_dim"]},
        "dataset_kwargs": {
            "create_inverse_triples": False  # æ·»åŠ åå‘ä¸‰å…ƒç»„
        },
        "loss": loss_name,
        "loss_kwargs": loss_kwargs,
        "optimizer": "Adam",
        "optimizer_kwargs": {
            "lr": cfg["training"]["learning_rate"],
            "weight_decay": cfg["training"]["regularization_coef"],
        },
        "negative_sampler": "bernoulli",  # ä¼ªç±»å‹è´Ÿé‡‡æ ·å™¨ å…¶ä»–è´Ÿé‡‡æ ·å™¨ "bernoulli"
        "negative_sampler_kwargs": {"num_negs_per_pos": cfg["training"]["neg_per_pos"]},
        "training_kwargs": {
            "num_epochs": cfg["training"]["num_epochs"],
            "batch_size": cfg["training"]["batch_size"],
            "callbacks": [early_stop_callback, checkpoint_callback],
        },
        "evaluator_kwargs": {
            "filtered": True,
            "batch_size": cfg["evaluation"]["batch_size"],
            "slice_size": cfg["evaluation"]["slice_size"],
        },
        "random_seed": 42,
        "device": cfg["training"]["device"],
        "use_tqdm": True,
    }

    try:
        start = time.time()
        result = pipeline(**pipeline_args)

        # æ˜¾å¼ä¿å­˜æœ€ç»ˆæ¨¡å‹å’Œè¯„ä¼°ç»“æœ
        result.save_to_directory(model_dir)
        logger.info(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {model_dir.absolute()}")

        return {"status": "completed"}
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        return {"error": str(e)}
    finally:
        # === æ–°å¢ï¼šæ¢å¤åŸå§‹æ—¥å¿—çº§åˆ« ===
        logging.getLogger("pykeen").setLevel(original_level)
        logging.getLogger("pykeen.pipeline").setLevel(original_level)
        # === ç»“æŸæ–°å¢éƒ¨åˆ† ===


# === ä¸»ç¨‹åº ===
if __name__ == "__main__":
    cfg, project_root = load_config()
    all_metrics = {}
    for name in ["RotatE"]:  # "DistMult","ComplEx","RotatE"
        all_metrics[name] = train_model(name, cfg, project_root)
    logger.info("=== æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ ===")